2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.type = squad
2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = word
2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.type = spacy
2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.language = en_core_web_sm
2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.pos_tags = False
2018-04-21 16:23:21,759 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.parse = False
2018-04-21 16:23:21,760 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_splitter.ner = False
2018-04-21 16:23:22,196 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_filter.type = pass_through
2018-04-21 16:23:22,196 - INFO - allennlp.common.params - dataset_reader.tokenizer.word_stemmer.type = pass_through
2018-04-21 16:23:22,196 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = None
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = None
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.type = characters
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.namespace = token_characters
2018-04-21 16:23:22,197 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.character_tokenizer.byte_encoding = utf-8
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.character_tokenizer.lowercase_characters = False
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.character_tokenizer.start_tokens = [259]
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.character_tokenizer.end_tokens = [260]
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - dataset_reader.lazy = False
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - validation_dataset_reader = None
2018-04-21 16:23:22,198 - INFO - allennlp.common.params - train_data_path = data/train.json
2018-04-21 16:23:22,198 - INFO - allennlp.commands.train - Reading training data from data/train.json
2018-04-21 16:23:22,201 - INFO - allennlp.data.dataset_readers.reading_comprehension.squad - Reading file at data/train.json
2018-04-21 16:23:22,692 - INFO - allennlp.data.dataset_readers.reading_comprehension.squad - Reading the dataset
2018-04-21 16:24:21,461 - INFO - allennlp.common.params - validation_data_path = data/dev.json
2018-04-21 16:24:21,462 - INFO - allennlp.commands.train - Reading validation data from data/dev.json
2018-04-21 16:24:21,465 - INFO - allennlp.data.dataset_readers.reading_comprehension.squad - Reading file at data/dev.json
2018-04-21 16:24:21,507 - INFO - allennlp.data.dataset_readers.reading_comprehension.squad - Reading the dataset
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - test_data_path = None
2018-04-21 16:24:34,270 - INFO - allennlp.commands.train - Creating a vocabulary using train, validation data.
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - vocabulary.directory_path = None
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - vocabulary.min_count = None
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2018-04-21 16:24:34,270 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2018-04-21 16:24:34,270 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
